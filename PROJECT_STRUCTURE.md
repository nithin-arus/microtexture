# Project Structure & Organization

This project maintains **complete separation** between data collection and research analysis pipelines.

## ðŸ“ **Data Collection Pipeline**

### **Core Files:**
```
main.py                          # Main data collection orchestrator
preprocess/
  â””â”€â”€ preprocess.py             # Image preprocessing
capture/
  â”œâ”€â”€ capture_image.py          # Image capture functionality
  â””â”€â”€ images/                   # ðŸ”„ OUTPUT: Captured images
features/
  â””â”€â”€ extract_features.py       # Feature extraction
analysis/
  â”œâ”€â”€ feature_extractor.py      # Core feature extraction
  â”œâ”€â”€ fractal_analysis.py       # Fractal dimension analysis
  â””â”€â”€ fractal_fitting.py        # Fractal surface fitting
```

### **Data Collection Outputs:**
```
data/
  â””â”€â”€ features.csv              # ðŸ”„ OUTPUT: Extracted features
capture/images/                 # ðŸ”„ OUTPUT: Raw captured images
fractal_overlays/               # ðŸ”„ OUTPUT: Fractal visualization overlays
```

---

## ðŸ”¬ **Research Analysis Pipeline**

### **Core Files:**
```
research/
  â”œâ”€â”€ __init__.py               # Main research package
  â”œâ”€â”€ research_analysis.py      # Main research orchestrator
  â”œâ”€â”€ models/
  â”‚   â”œâ”€â”€ supervised_models.py  # Classification models
  â”‚   â””â”€â”€ anomaly_detection.py  # Anomaly detection models
  â”œâ”€â”€ utils/
  â”‚   â””â”€â”€ data_utils.py         # Data processing utilities
  â”œâ”€â”€ visualization/
  â”‚   â””â”€â”€ visualizers.py        # Visualization tools
  â”œâ”€â”€ evaluation/
  â”‚   â””â”€â”€ evaluators.py         # Model evaluation tools
  â””â”€â”€ README.md                 # Research framework documentation

run_research_analysis.py       # CLI interface for research analysis
```

### **Research Analysis Outputs:**
```
research_output/                # ðŸ”„ OUTPUT: All research results
  â”œâ”€â”€ research_report.md        # Comprehensive analysis report
  â”œâ”€â”€ visualizations/           # All plots and charts
  â”‚   â”œâ”€â”€ model_comparison.png
  â”‚   â”œâ”€â”€ feature_importance.png
  â”‚   â”œâ”€â”€ correlation_analysis.png
  â”‚   â”œâ”€â”€ dimensionality_reduction.png
  â”‚   â”œâ”€â”€ clustering_results.png
  â”‚   â”œâ”€â”€ anomaly_detection.png
  â”‚   â””â”€â”€ ...
  â”œâ”€â”€ evaluation/               # Detailed evaluation metrics
  â”œâ”€â”€ models/                   # Trained model files
  â””â”€â”€ statistical_analysis/     # Statistical test results
```

---

## ðŸ”— **Pipeline Independence**

### **âœ… Complete Separation:**
- **No cross-dependencies** between pipelines
- **Independent execution** - can run either without the other
- **Separate output folders** - no conflicts
- **Modular design** - easy to extend either pipeline

### **ðŸ”„ Data Flow:**
```
1. Data Collection: main.py â†’ data/features.csv
                             â†“
2. Research Analysis: run_research_analysis.py â†’ research_output/
```

---

## ðŸš€ **Usage**

### **Data Collection Only:**
```bash
# Collect data and extract features
python main.py

# Outputs:
# - data/features.csv
# - capture/images/*.jpg  
# - fractal_overlays/*.png
```

### **Research Analysis Only:**
```bash
# Analyze existing feature data
python run_research_analysis.py

# Or programmatically:
from research import run_quick_analysis
analyzer = run_quick_analysis("data/features.csv")

# Outputs:
# - research_output/ (complete analysis results)
```

### **Complete Workflow:**
```bash
# Step 1: Collect data
python main.py

# Step 2: Analyze data  
python run_research_analysis.py

# Result: Both data/ and research_output/ directories populated
```

---

## ðŸ“¦ **Dependencies**

### **Data Collection Dependencies:**
```
opencv-python>=4.8.0
numpy>=1.24.0
pandas>=2.0.0
scikit-image>=0.20.0
scipy>=1.10.0
matplotlib>=3.7.0
picamera2>=0.3.12    # For Raspberry Pi camera
tqdm>=4.65.0
PyWavelets>=1.4.0
mahotas>=1.4.0
```

### **Research Analysis Dependencies:**
```
# Core (required)
scikit-learn>=1.0.0
seaborn>=0.12.0
umap-learn>=0.5.0
joblib>=1.2.0

# Optional (enhanced functionality)
xgboost>=1.7.0       # For XGBoost classifier
lightgbm>=3.3.0      # For LightGBM classifier
tensorflow>=2.10.0   # For autoencoder anomaly detection
shap>=0.41.0         # For SHAP explainability
lime>=0.2.0          # For LIME explainability
```

---

## ðŸ”§ **Configuration**

Both pipelines are independently configurable:

- **Data Collection**: Modify parameters in `main.py` and individual modules
- **Research Analysis**: Use CLI flags or modify `ResearchAnalyzer` parameters

No shared configuration files = no conflicts between pipelines. 